import sys
import random
import torch
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

print("ğŸ Python being used:", sys.executable)


CHECKPOINT_PATH = "./codet5_chunked/chunk_9"   
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"


print(f"ğŸš€ Loading model from: {CHECKPOINT_PATH}")
tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT_PATH)
model = AutoModelForSeq2SeqLM.from_pretrained(CHECKPOINT_PATH, trust_remote_code=True)
model.to(DEVICE)
model.eval()

print(f"âœ… Model loaded successfully on {DEVICE.upper()}.")



confused_responses = [
    "Are you trying to confuse me? ğŸ« ",
    "I have no idea what just happened. ğŸ¤¯",
    "Uhh... what did I just read? ğŸ‘€",
    "My circuits are overheating... try again? ğŸ§ ğŸ”¥",
    "That made less sense than a semicolon in an if-statement ğŸ˜µ",
    "Syntax error in my brain. Please rephrase. ğŸ’«",
    "I'm gonna pretend I didnâ€™t see that. ğŸ™ˆ",
    "404 explanation not found. ğŸš«",
    "You broke me. Again. ğŸ˜’",
    "Explain like I'm five, please. ğŸ§¸",
    "That's not even wrong. It's... something else. ğŸ¤¡",
    "I need coffee for this one. â˜•",
    "Huh? I'm just a broken AI, not a mind reader. ğŸ˜©",
]


def main():
    print("\nğŸ”¥ AI Code Explainer is ready! Type your C++ code below.")
    print("Type 'exit' or 'quit' to stop.\n")
    
    while True:
        user_input = input("ğŸ’€ Ask AI: ")

        if user_input.lower() in ["exit", "quit"]:
            print("ğŸ‘‹ Goodbye!")
            break

        if not user_input.strip():
            print("âš ï¸ Empty input. Try again.")
            continue

       
        inputs = tokenizer(user_input, return_tensors="pt", truncation=True, padding=True).to(DEVICE)
        outputs = model.generate(
            **inputs,
            max_length=128,
            num_beams=5,
            early_stopping=True
        )
        explanation = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()

       
        if len(explanation) < 3:
            explanation = random.choice(confused_responses)

        print("ğŸ¤– AI says:", explanation, "\n")

        
        with open("log.txt", "a", encoding="utf-8") as f:
            f.write(f"Input: {user_input}\nOutput: {explanation}\n\n")

if __name__ == "__main__":
    main()
